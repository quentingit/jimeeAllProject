{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the rent in Paris using multiple linear regression with dummies variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will carry out a case study to estimate the rent by explaining the most influential boroughs of Paris the French capital. The used method is the Multiple Linear Regression with variable dummies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('beforeafter.csv')\n",
    "\n",
    "# Cleaning all observations with nan values\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation of the categorical variable named \"arrondissement\" into five dummies variables each of these ones represents an \"arrondissement\".\n",
    "\n",
    "Construction of a global dataframe containing the five dummies variables that have just been constructed plus the two variables \"price\" and \"surface\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_0</th>\n",
       "      <th>period_1</th>\n",
       "      <th>followers</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5509.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9620.0</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   period_0  period_1  followers  likes\n",
       "0         1         0      279.0   15.0\n",
       "1         1         0     5509.0  360.0\n",
       "2         1         0      453.0   65.0\n",
       "3         1         0     1231.0   53.0\n",
       "4         1         0     9620.0  623.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.DataFrame({'period': dataset.period.astype(str)})\n",
    "dummies = pd.get_dummies(dummies)\n",
    "dataset = pd.concat([dummies, dataset], axis=1)\n",
    "del dataset['period']\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Construction of X data set containing the prediction variables as well as the vector y containing the data to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('followers', axis=1)\n",
    "y = dataset['followers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting of X and y into two parts each, which will be used for training and testing the model. The part reserved for training contains 80% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the multiple linear regression model using the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the results of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display of the model parameters such as the constant and the coefficients of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Const: \n",
      " 692.1957622831239\n",
      "Coefficients: \n",
      " [-262.15944618  262.15944618    9.78291549]\n"
     ]
    }
   ],
   "source": [
    "print('Const: \\n', regressor.intercept_)\n",
    "print('Coefficients: \\n', regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of the theta parameters\n",
    "We will check if the vector theta gives the same results or not. We must not forget to add a composite column of 1 in X_train that I named X_train_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1427.32316878   775.34351357  1300.96226403  1965.56352984\n",
      "   163.42487133  1050.06161534    32.84421801]\n"
     ]
    }
   ],
   "source": [
    "X_train_1 = np.append(arr = np.ones((X_train.shape[0], 1)).astype(int), values = X_train, axis = 1)\n",
    "\n",
    "theta = np.linalg.inv(X_train_1.T.dot(X_train_1)).dot(X_train_1.T).dot(y_train)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are different from those given above. The reason is that among dummies variables there are some that are collinear.\n",
    "You should delete a given variable. However, the deletion will not be randomly. There is a selection method\n",
    "variables that have no interest in the model and that it is better to delete them one by one. This method is called \"Backward Elimination\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping all the variables in order to select which one to be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels.formula.api' has no attribute 'OLS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f4e990486d7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m X_opt = X_train[['const', 'arrondissement_1.0', 'arrondissement_2.0','arrondissement_3.0', \n\u001b[0;32m      8\u001b[0m                  'arrondissement_4.0', 'arrondissement_10.0', 'surface']]\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mregressor_OLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mregressor_OLS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'statsmodels.formula.api' has no attribute 'OLS'"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "X_train = pd.concat([pd.DataFrame(np.ones((X_train.shape[0], 1)).astype(int),\n",
    "                                  index=X_train.index), X_train], axis=1)\n",
    "X_train.rename(columns={0: 'const'}, inplace=True)\n",
    "\n",
    "X_opt = X_train[['const', 'period_1', 'period_1','arrondissement_3.0', \n",
    "                 'arrondissement_4.0', 'arrondissement_10.0', 'surface']]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By investigating the \"coef\" column, one would normally find the same results as with the established \"regressor\" model. However, the cause of this difference is as it was explained it is the collinearity between some dummies variables. We will see after an elimination of a variable that the results will be identical with \"regressor\", \"theta\" and \"OLS Regression\".\n",
    "\n",
    "In the middle table, there is a column that displays the p-values of each coefficient. The first variable to be deleted is the one with the largest p-value and which exceeds 5% which is \"arrondissement_3.0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimination of \"arrondissement_3.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results with \"regressor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Const: \n",
      " 21.25560346291195\n",
      "Coefficients: \n",
      " [ 244.58970026   96.85743072  179.07947836 -266.20902165   32.84421801]\n"
     ]
    }
   ],
   "source": [
    "X_opt = X_train[['arrondissement_1.0', 'arrondissement_2.0', \n",
    "                 'arrondissement_4.0', 'arrondissement_10.0', 'surface']]\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_opt, y_train)\n",
    "\n",
    "print('Const: \\n', regressor.intercept_)\n",
    "print('Coefficients: \\n', regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results with \"theta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  21.25560346  244.58970026   96.85743072  179.07947836 -266.20902165\n",
      "   32.84421801]\n"
     ]
    }
   ],
   "source": [
    "X_opt = X_train[['const', 'arrondissement_1.0', 'arrondissement_2.0', \n",
    "                 'arrondissement_4.0', 'arrondissement_10.0', 'surface']]\n",
    "\n",
    "theta = np.linalg.inv(X_opt.T.dot(X_opt)).dot(X_opt.T).dot(y_train)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results with \"regressor_OLS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels.formula.api' has no attribute 'OLS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-370fdb383d71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mregressor_OLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mregressor_OLS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'statsmodels.formula.api' has no attribute 'OLS'"
     ]
    }
   ],
   "source": [
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "theta = np.linalg.inv(X_opt.T.dot(X_opt)).dot(X_opt.T).dot(y_train)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the results of the three methods are identical in eliminating the cause of collinearity. However, to go further by seeking a more compact model, we must continue to eliminate variables that are not significant by examining their p-values. So, the variable to eliminate is the constant. For the rest, we study only the OLS regression method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimination of the constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels.formula.api' has no attribute 'OLS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fc747648c39b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m X_opt = X_train[['arrondissement_1.0', 'arrondissement_2.0', 'arrondissement_4.0',\n\u001b[0;32m      2\u001b[0m                  'arrondissement_10.0', 'surface']]\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mregressor_OLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mregressor_OLS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'statsmodels.formula.api' has no attribute 'OLS'"
     ]
    }
   ],
   "source": [
    "X_opt = X_train[['arrondissement_1.0', 'arrondissement_2.0', 'arrondissement_4.0',\n",
    "                 'arrondissement_10.0', 'surface']]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "theta = np.linalg.inv(X_opt.T.dot(X_opt)).dot(X_opt.T).dot(y_train)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we continue the elimination procedure, we should eliminate the variable \"arrondissement_2.0\". However, this one can be significant. For this, we must consider when eliminating variables the parameters \"R-squared\" and \"Adj. R-squared\". If in each variable elimination they increase, this implies that the model is improved by eliminating the variable in question. Otherwise, it is better to keep it and stopping the variable elimination procedure. \n",
    "\n",
    "Let's see what it gives the elimination of \"arrondissement_2.0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimination of \"arrondissement_2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 234.34406131  174.08828927 -266.10853118   33.27360753]\n"
     ]
    }
   ],
   "source": [
    "theta = np.linalg.inv(X_opt.T.dot(X_opt)).dot(X_opt.T).dot(y_train)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels.formula.api' has no attribute 'OLS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-918586b638ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m X_opt = X_train[['arrondissement_1.0', 'arrondissement_4.0', \n\u001b[0;32m      2\u001b[0m                  'arrondissement_10.0', 'surface']]\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mregressor_OLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mregressor_OLS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'statsmodels.formula.api' has no attribute 'OLS'"
     ]
    }
   ],
   "source": [
    "X_opt = X_train[['arrondissement_1.0', 'arrondissement_4.0', \n",
    "                 'arrondissement_10.0', 'surface']]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noted that the values of the parameters \"R-squared\" and \"Adj.r-squared\" have not changed by eliminating \"arrondissement_2.0\". The model has consecontly kept its optimum. Since such a variable has a slightly higher p-value still at 5% and its elimination has not degraded the model, we will eliminate it by keeping the last model which is obtained using only \"arrondissement_1.0\", \"arrondissement_4.0\", \"arrondissement_10.0\" and \"surface\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, consider the coefficients corresponding to these variables in order to estimate the rent in Paris. First of all, we note that the price of the rent of a square meter is estimated at 33.27 euros independently of the boroughs: \"arrondissement_2.0\" and \"arrondissement_3.0\". These last two variables have no infulence on the rent price. For example, a studio of 27 m2 will be rented at 27x33.2736 = 900 euros in these two districts.\n",
    "\n",
    "Indeed, the rent will be more expensive in boroughs \"arrondissement_1.0\" then \"arrondissement_4.0\". The same area of the studio will be rented at 900+234.34 = 1134 euros and 900+174 = 1074 euros in \"arrondissement_1.0\" and \"arrondissement_4.0\" respectively. These ones are certainly the chic districts in Paris.\n",
    "\n",
    "On the other hand, the district \"arrondissement_10.0\" suffers apparently from a bad reputation. The rent in this borough is penalized 266.10 euros less. That is to say, the same area of such a studio will be rented at 900-266.10 = 634 euros. Such a district may be a very popular borough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
